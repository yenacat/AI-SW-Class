{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 2.5\n",
      "Gamma: 1e-05\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "trains = np.array(\n",
    "    [\n",
    "        [150, 200],\n",
    "        [200, 250],\n",
    "        [100, 250],\n",
    "        [150, 300],\n",
    "        [350, 100],\n",
    "        [400, 200],\n",
    "        [400, 300],\n",
    "        [350, 400],\n",
    "    ],\n",
    "    dtype=np.float32,\n",
    ")\n",
    "\n",
    "labels = np.array([0, 0, 0, 0, 1, 1, 1, 1])\n",
    "\n",
    "svm = cv2.ml.SVM_create()\n",
    "\n",
    "svm.setType(cv2.ml.SVM_C_SVC)\n",
    "\n",
    "# svm.setKernel(cv2.ml.SVM_LINEAR)\n",
    "svm.setKernel(cv2.ml.SVM_RBF)\n",
    "\n",
    "svm.trainAuto(trains, cv2.ml.ROW_SAMPLE, labels)\n",
    "\n",
    "print(\"C:\", svm.getC())\n",
    "print(\"Gamma:\", svm.getGamma())\n",
    "\n",
    "w, h = 500, 500\n",
    "img = np.zeros((w, h, 3), dtype=np.uint8)\n",
    "\n",
    "for y in range(h):\n",
    "    for x in range(w):\n",
    "        test = np.array([[x, y]], dtype=np.float32)\n",
    "        _, res = svm.predict(test)\n",
    "        ret = int(res[0][0])\n",
    "\n",
    "        if ret == 0:\n",
    "            img[y, x] = [128, 128, 255]\n",
    "        else:\n",
    "            img[y, x] = [128, 255, 128]\n",
    "\n",
    "color = [(0, 0, 128), (0, 128, 0)]\n",
    "for i in range(trains.shape[0]):\n",
    "    x = int(trains[i][0])\n",
    "    y = int(trains[i][1])\n",
    "    l = labels[i]\n",
    "    cv2.circle(img, (x, y), 5, color[l], -1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow(\"SVM Classification\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "5\n",
      "3\n",
      "8\n",
      "4\n",
      "1\n",
      "train_desc.shape: (5000, 324)\n",
      "train_labels.shape: (5000,)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "digits = cv2.imread(\"digits.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "h, w = digits.shape[:2]\n",
    "oldx, oldy = -1, -1\n",
    "\n",
    "\n",
    "def on_mouse(event, x, y, flags, _):\n",
    "    global oldx, oldy\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        oldx, oldy = x, y\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        oldx, oldy = -1, -1\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "            cv2.line(img, (oldx, oldy), (x, y), (255, 255, 255), 40, cv2.LINE_AA)\n",
    "            oldx, oldy = x, y\n",
    "            cv2.imshow(\"img\", img)\n",
    "\n",
    "\n",
    "hog = cv2.HOGDescriptor((20, 20), (10, 10), (5, 5), (5, 5), 9)\n",
    "\n",
    "cells = [np.hsplit(row, w // 20) for row in np.vsplit(digits, h // 20)]\n",
    "cells = np.array(cells)\n",
    "cells = cells.reshape(-1, 20, 20)\n",
    "\n",
    "desc = []\n",
    "for img in cells:\n",
    "    desc.append(hog.compute(img))\n",
    "\n",
    "train_desc = np.array(desc).squeeze().astype(np.float32)\n",
    "train_labels = np.repeat(np.arange(10), len(train_desc) // 10)\n",
    "img = np.zeros((400, 400), np.uint8)\n",
    "\n",
    "\n",
    "svm = cv2.ml.SVM_create()\n",
    "svm.setType(cv2.ml.SVM_C_SVC)\n",
    "svm.setKernel(cv2.ml.SVM_RBF)\n",
    "svm.setC(2.5)\n",
    "svm.setGamma(0.50625)\n",
    "svm.train(train_desc, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.setMouseCallback(\"img\", on_mouse)\n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey()\n",
    "\n",
    "    if key == 27:\n",
    "        break\n",
    "    elif key == ord(\" \"):\n",
    "        test_image = cv2.resize(img, (20, 20), interpolation=cv2.INTER_AREA)\n",
    "        test_desc = hog.compute(test_image).reshape(-1, 1).T\n",
    "\n",
    "        _, res = svm.predict(test_desc)\n",
    "        print(int(res[0, 0]))\n",
    "\n",
    "        img.fill(0)\n",
    "        cv2.imshow(\"img\", img)\n",
    "\n",
    "print(\"train_desc.shape:\", train_desc.shape)\n",
    "print(\"train_labels.shape:\", train_labels.shape)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptor Size: 324\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "oldx, oldy = -1, -1\n",
    "\n",
    "\n",
    "def on_mouse(event, x, y, flags, _):\n",
    "    global oldx, oldy\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        oldx, oldy = x, y\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        oldx, oldy = -1, -1\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "            cv2.line(img, (oldx, oldy), (x, y), (255, 255, 255), 40, cv2.LINE_AA)\n",
    "            oldx, oldy = x, y\n",
    "            cv2.imshow(\"img\", img)\n",
    "\n",
    "\n",
    "def norm_digit(img):\n",
    "    m = cv2.moments(img)\n",
    "    cx = m[\"m10\"] / m[\"m00\"]\n",
    "    cy = m[\"m01\"] / m[\"m00\"]\n",
    "    h, w = img.shape[:2]\n",
    "    aff = np.array([[1, 0, w / 2 - cx], [0, 1, h / 2 - cy]], dtype=np.float32)\n",
    "    dst = cv2.warpAffine(img, aff, (0, 0))\n",
    "    return dst\n",
    "\n",
    "\n",
    "# 학습 데이터 & 레이블 행렬 생성\n",
    "\n",
    "digits = cv2.imread(\"digits.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "if digits is None:\n",
    "    print(\"Image load failed!\")\n",
    "    sys.exit()\n",
    "\n",
    "h, w = digits.shape[:2]\n",
    "hog = cv2.HOGDescriptor((20, 20), (10, 10), (5, 5), (5, 5), 9)\n",
    "print(\"Descriptor Size:\", hog.getDescriptorSize())\n",
    "\n",
    "cells = [np.hsplit(row, w // 20) for row in np.vsplit(digits, h // 20)]\n",
    "cells = np.array(cells)\n",
    "cells = cells.reshape(-1, 20, 20)  # shape=(5000, 20, 20)\n",
    "\n",
    "desc = []\n",
    "for img in cells:\n",
    "    img = norm_digit(img)\n",
    "    desc.append(hog.compute(img))\n",
    "\n",
    "train_desc = np.array(desc)\n",
    "train_desc = train_desc.squeeze().astype(np.float32)\n",
    "train_labels = np.repeat(np.arange(10), len(train_desc) / 10)\n",
    "\n",
    "# SVM 학습\n",
    "\n",
    "svm = cv2.ml.SVM_create()\n",
    "svm.setType(cv2.ml.SVM_C_SVC)\n",
    "svm.setKernel(cv2.ml.SVM_RBF)\n",
    "svm.setC(2.5)\n",
    "svm.setGamma(0.50625)\n",
    "\n",
    "svm.train(train_desc, cv2.ml.ROW_SAMPLE, train_labels)\n",
    "# svm.save('svmdigits.yml')\n",
    "\n",
    "# 사용자 입력 영상에 대해 예측\n",
    "\n",
    "img = np.zeros((400, 400), np.uint8)\n",
    "\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.setMouseCallback(\"img\", on_mouse)\n",
    "\n",
    "while True:\n",
    "    key = cv2.waitKey()\n",
    "\n",
    "    if key == 27:\n",
    "        break\n",
    "    elif key == ord(\" \"):\n",
    "        test_image = cv2.resize(img, (20, 20), interpolation=cv2.INTER_AREA)\n",
    "        test_image = norm_digit(test_image)\n",
    "        test_desc = hog.compute(test_image).reshape(-1, 1).T\n",
    "\n",
    "        _, res = svm.predict(test_desc)\n",
    "        print(int(res[0, 0]))\n",
    "\n",
    "        img.fill(0)\n",
    "        cv2.imshow(\"img\", img)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "src = cv2.imread(\"flowers.jpg\")\n",
    "\n",
    "data = src.reshape(-1, 3).astype(np.float32)\n",
    "\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "\n",
    "for K in range(2, 10):\n",
    "    ret, label, center = cv2.kmeans(\n",
    "        data, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS\n",
    "    )\n",
    "\n",
    "    center = np.uint8(center)\n",
    "    dst = center[label.flatten()]\n",
    "    dst = dst.reshape(src.shape)\n",
    "\n",
    "    cv2.imshow(f\"K={K}\", dst)\n",
    "    cv2.waitKey()\n",
    "    cv2.destroyWindow(f\"K={K}\")\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (11.94)\n",
      "3 (85.28)\n",
      "6 (98.98)\n",
      "8 (91.88)\n",
      "7 (100.00)\n",
      "4 (100.00)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "oldx, oldy = -1, -1\n",
    "\n",
    "\n",
    "def on_mouse(event, x, y, flags, _):\n",
    "    global oldx, oldy\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        oldx, oldy = x, y\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        oldx, oldy = -1, -1\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "            cv2.line(img, (oldx, oldy), (x, y), (255, 255, 255), 40, cv2.LINE_AA)\n",
    "            oldx, oldy = x, y\n",
    "            cv2.imshow(\"img\", img)\n",
    "\n",
    "\n",
    "net = cv2.dnn.readNet(\"mnist_cnn.pb\")\n",
    "\n",
    "img = np.zeros((400, 400), np.uint8)\n",
    "\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.setMouseCallback(\"img\", on_mouse)\n",
    "\n",
    "while True:\n",
    "    c = cv2.waitKey()\n",
    "\n",
    "    if c == ord(\" \"):\n",
    "        blob = cv2.dnn.blobFromImage(img, 1 / 255.0, (28, 28))\n",
    "        net.setInput(blob)\n",
    "        prob = net.forward()\n",
    "\n",
    "        _, maxVal, _, maxLoc = cv2.minMaxLoc(prob)\n",
    "        digit = maxLoc[0]\n",
    "\n",
    "        print(f\"{digit} ({maxVal * 100:4.2f})\")\n",
    "\n",
    "        img.fill(0)\n",
    "        cv2.imshow(\"img\", img)\n",
    "    elif c == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "filename = \"beagle.jpg\"\n",
    "\n",
    "img = cv2.imread(filename)\n",
    "\n",
    "model = r\"C:\\Users\\UserK\\projects\\Python\\20250425\\googlenet\\bvlc_googlenet.caffemodel\"\n",
    "config = r\"C:\\Users\\UserK\\projects\\Python\\20250425\\googlenet\\deploy.prototxt\"\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "classNames = None\n",
    "with open(\n",
    "    r\"C:\\Users\\UserK\\projects\\Python\\20250425\\googlenet\\classification_classes_ILSVRC2012.txt\",\n",
    "    \"rt\",\n",
    ") as f:\n",
    "    classNames = f.read().rstrip(\"\\n\").split(\"\\n\")\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (224, 224), (104, 117, 123))\n",
    "net.setInput(blob, \"data\")\n",
    "prob = net.forward()\n",
    "\n",
    "out = prob.flatten()\n",
    "classId = np.argmax(out)\n",
    "confidence = out[classId]\n",
    "\n",
    "text = f\"{classNames[classId]} ({confidence * 100:4.2f}%)\"\n",
    "cv2.putText(\n",
    "    img, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 1, cv2.LINE_AA\n",
    ")\n",
    "\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "oldx, oldy = -1, -1\n",
    "\n",
    "\n",
    "def on_mouse(event, x, y, flags, _):\n",
    "    global oldx, oldy\n",
    "\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        oldx, oldy = x, y\n",
    "\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        oldx, oldy = -1, -1\n",
    "\n",
    "    elif event == cv2.EVENT_MOUSEMOVE:\n",
    "        if flags & cv2.EVENT_FLAG_LBUTTON:\n",
    "            cv2.line(img, (oldx, oldy), (x, y), (255, 255, 255), 24, cv2.LINE_AA)\n",
    "            oldx, oldy = x, y\n",
    "            cv2.imshow(\"img\", img)\n",
    "\n",
    "\n",
    "def norm_hangul(img):\n",
    "    m = cv2.moments(img)\n",
    "    cx = m[\"m10\"] / m[\"m00\"]\n",
    "    cy = m[\"m01\"] / m[\"m00\"]\n",
    "    h, w = img.shape[:2]\n",
    "    aff = np.array([[1, 0, w / 2 - cx], [0, 1, h / 2 - cy]], dtype=np.float32)\n",
    "    dst = cv2.warpAffine(img, aff, (0, 0))\n",
    "    return dst\n",
    "\n",
    "\n",
    "# 네트워크 불러오기\n",
    "net = cv2.dnn.readNet(\"tensorflow-hangul-recognition-master/korean_recognition.pb\")\n",
    "\n",
    "if net.empty():\n",
    "    print(\"Network load failed!\")\n",
    "    sys.exit()\n",
    "\n",
    "# 한글 파일 불러오기\n",
    "classNames = None\n",
    "with open(\n",
    "    \"tensorflow-hangul-recognition-master/labels/256-common-hangul.txt\",\n",
    "    \"rt\",\n",
    "    encoding=\"utf-8\",\n",
    ") as f:\n",
    "    classNames = f.read().rstrip(\"\\n\").split(\"\\n\")\n",
    "\n",
    "# 마우스로 한글을 입력할 새 영상\n",
    "img = np.zeros((400, 400), np.uint8)\n",
    "\n",
    "cv2.imshow(\"img\", img)\n",
    "cv2.setMouseCallback(\"img\", on_mouse)\n",
    "\n",
    "while True:\n",
    "    c = cv2.waitKey()\n",
    "\n",
    "    if c == 27:\n",
    "        break\n",
    "    elif c == ord(\" \"):\n",
    "        img = norm_hangul(img)\n",
    "        blob = cv2.dnn.blobFromImage(img, 1, (64, 64))\n",
    "        net.setInput(blob)\n",
    "        out = net.forward()  # out.shape=(1, 256)\n",
    "\n",
    "        out = out.flatten()\n",
    "        classId = np.argmax(out)\n",
    "        confidence = out[classId]\n",
    "\n",
    "        print(f\"{classNames[classId]} ({confidence * 100:4.2f}%)\")\n",
    "\n",
    "        img.fill(0)\n",
    "        cv2.imshow(\"img\", img)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "model = \"face_detect/res10_300x300_ssd_iter_140000_fp16.caffemodel\"\n",
    "config = \"face_detect/deploy.prototxt\"\n",
    "# model = 'opencv_face_detector/opencv_face_detector_uint8.pb'\n",
    "# config = 'opencv_face_detector/opencv_face_detector.pbtxt'\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Camera open failed!\")\n",
    "    sys.exit()\n",
    "\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    print(\"Net open failed!\")\n",
    "    sys.exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1, (300, 300), (104, 177, 123))\n",
    "    net.setInput(blob)\n",
    "    out = net.forward()\n",
    "\n",
    "    detect = out[0, 0, :, :]\n",
    "    (h, w) = frame.shape[:2]\n",
    "\n",
    "    for i in range(detect.shape[0]):\n",
    "        confidence = detect[i, 2]\n",
    "        if confidence < 0.5:\n",
    "            break\n",
    "\n",
    "        x1 = int(detect[i, 3] * w)\n",
    "        y1 = int(detect[i, 4] * h)\n",
    "        x2 = int(detect[i, 5] * w)\n",
    "        y2 = int(detect[i, 6] * h)\n",
    "\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0))\n",
    "\n",
    "        label = f\"Face: {confidence:4.2f}\"\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            label,\n",
    "            (x1, y1 - 1),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.8,\n",
    "            (0, 255, 0),\n",
    "            1,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 모델 & 설정 파일\n",
    "model = \"yolo_v3/yolov3.weights\"\n",
    "config = \"yolo_v3/yolov3.cfg\"\n",
    "class_labels = \"yolo_v3/coco.names\"\n",
    "confThreshold = 0.5\n",
    "nmsThreshold = 0.4\n",
    "\n",
    "# 테스트 이미지 파일\n",
    "img_files = [\n",
    "    r\"C:\\Users\\UserK\\projects\\Python\\20250425\\yolo_v3\\dog.jpg\",\n",
    "    r\"C:\\Users\\UserK\\projects\\Python\\20250425\\yolo_v3\\person.jpg\",\n",
    "    r\"C:\\Users\\UserK\\projects\\Python\\20250425\\yolo_v3\\sheep.jpg\",\n",
    "    r\"C:\\Users\\UserK\\projects\\Python\\20250425\\yolo_v3\\beagle.jpg\",\n",
    "]\n",
    "\n",
    "# 네트워크 생성\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    print(\"Net open failed!\")\n",
    "    sys.exit()\n",
    "\n",
    "# 클래스 이름 불러오기\n",
    "\n",
    "classes = []\n",
    "with open(class_labels, \"rt\") as f:\n",
    "    classes = f.read().rstrip(\"\\n\").split(\"\\n\")\n",
    "\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "# 출력 레이어 이름 받아오기\n",
    "\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "# output_layers = ['yolo_82', 'yolo_94', 'yolo_106']\n",
    "\n",
    "# 실행\n",
    "\n",
    "for f in img_files:\n",
    "    img = cv2.imread(f)\n",
    "\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    # 블롭 생성 & 추론\n",
    "    blob = cv2.dnn.blobFromImage(img, 1 / 255.0, (320, 320), swapRB=True)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "\n",
    "    # outs는 3개의 ndarray 리스트.\n",
    "    # outs[0].shape=(507, 85), 13*13*3=507\n",
    "    # outs[1].shape=(2028, 85), 26*26*3=2028\n",
    "    # outs[2].shape=(8112, 85), 52*52*3=8112\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            # detection: 4(bounding box) + 1(objectness_score) + 80(class confidence)\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > confThreshold:\n",
    "                # 바운딩 박스 중심 좌표 & 박스 크기\n",
    "                cx = int(detection[0] * w)\n",
    "                cy = int(detection[1] * h)\n",
    "                bw = int(detection[2] * w)\n",
    "                bh = int(detection[3] * h)\n",
    "\n",
    "                # 바운딩 박스 좌상단 좌표\n",
    "                sx = int(cx - bw / 2)\n",
    "                sy = int(cy - bh / 2)\n",
    "\n",
    "                boxes.append([sx, sy, bw, bh])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(int(class_id))\n",
    "\n",
    "    # 비최대 억제\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "\n",
    "    for i in indices:\n",
    "        sx, sy, bw, bh = boxes[i]\n",
    "        label = f\"{classes[class_ids[i]]}: {confidences[i]:.2}\"\n",
    "        color = colors[class_ids[i]]\n",
    "        cv2.rectangle(img, (sx, sy, bw, bh), color, 2)\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            label,\n",
    "            (sx, sy - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.7,\n",
    "            color,\n",
    "            2,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "    t, _ = net.getPerfProfile()\n",
    "    label = \"Inference time: %.2f ms\" % (t * 1000.0 / cv2.getTickFrequency())\n",
    "    cv2.putText(\n",
    "        img, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 1, cv2.LINE_AA\n",
    "    )\n",
    "\n",
    "    cv2.imshow(\"img\", img)\n",
    "    cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 모델 & 설정 파일\n",
    "model = 'openpose/pose_iter_440000.caffemodel'\n",
    "config = 'openpose/pose_deploy_linevec.prototxt'\n",
    "\n",
    "# 포즈 점 개수, 점 연결 개수, 연결 점 번호 쌍\n",
    "nparts = 18\n",
    "npairs = 17\n",
    "pose_pairs = [(1, 2), (2, 3), (3, 4),  # 왼팔\n",
    "              (1, 5), (5, 6), (6, 7),  # 오른팔\n",
    "              (1, 8), (8, 9), (9, 10),  # 왼쪽다리\n",
    "              (1, 11), (11, 12), (12, 13),  # 오른쪽다리\n",
    "              (1, 0), (0, 14), (14, 16), (0, 15), (15, 17)]  # 얼굴\n",
    "\n",
    "# 테스트 이미지 파일\n",
    "img_files = ['pose1.jpg', 'pose2.jpg', 'pose3.jpg']\n",
    "\n",
    "# 네트워크 생성\n",
    "net = cv2.dnn.readNet(model, config)\n",
    "\n",
    "if net.empty():\n",
    "    print('Net open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "for f in img_files:\n",
    "    img = cv2.imread(f)\n",
    "\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    # 블롭 생성 & 추론\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255., (368, 368))\n",
    "    net.setInput(blob)\n",
    "    out = net.forward()  # out.shape=(1, 57, 46, 46)\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # 검출된 점 추출\n",
    "    points = []\n",
    "    for i in range(nparts):\n",
    "        heatMap = out[0, i, :, :]\n",
    "\n",
    "        '''\n",
    "        heatImg = cv2.normalize(heatMap, None, 0, 255, cv2.NORM_MINMAX, cv2.CV_8U)\n",
    "        heatImg = cv2.resize(heatImg, (w, h))\n",
    "        heatImg = cv2.cvtColor(heatImg, cv2.COLOR_GRAY2BGR)\n",
    "        heatImg = cv2.addWeighted(img, 0.5, heatImg, 0.5, 0)\n",
    "        cv2.imshow('heatImg', heatImg)\n",
    "        cv2.waitKey()\n",
    "        '''\n",
    "\n",
    "        _, conf, _, point = cv2.minMaxLoc(heatMap)\n",
    "        x = int(w * point[0] / out.shape[3])\n",
    "        y = int(h * point[1] / out.shape[2])\n",
    "\n",
    "        points.append((x, y) if conf > 0.1 else None)  # heat map threshold=0.1\n",
    "\n",
    "    # 검출 결과 영상 만들기\n",
    "    for pair in pose_pairs:\n",
    "        p1 = points[pair[0]]\n",
    "        p2 = points[pair[1]]\n",
    "\n",
    "        if p1 is None or p2 is None:\n",
    "            continue\n",
    "\n",
    "        cv2.line(img, p1, p2, (0, 255, 0), 3, cv2.LINE_AA)\n",
    "        cv2.circle(img, p1, 4, (0, 0, 255), -1, cv2.LINE_AA)\n",
    "        cv2.circle(img, p2, 4, (0, 0, 255), -1, cv2.LINE_AA)\n",
    "\n",
    "    # 추론 시간 출력\n",
    "    t, _ = net.getPerfProfile()\n",
    "    label = 'Inference time: %.2f ms' % (t * 1000.0 / cv2.getTickFrequency())\n",
    "    cv2.putText(img, label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                0.7, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "    cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "def decode(scores, geometry, scoreThreshold):\n",
    "    detections = []\n",
    "    confidences = []\n",
    "\n",
    "    # geometry.shape=(1, 5, 80, 80)\n",
    "    # scores.shape=(1, 1, 80, 80)\n",
    "\n",
    "    height = scores.shape[2]\n",
    "    width = scores.shape[3]\n",
    "\n",
    "    for y in range(0, height):\n",
    "        # Extract data from scores\n",
    "        scoresData = scores[0][0][y]\n",
    "        x0_data = geometry[0][0][y]\n",
    "        x1_data = geometry[0][1][y]\n",
    "        x2_data = geometry[0][2][y]\n",
    "        x3_data = geometry[0][3][y]\n",
    "        anglesData = geometry[0][4][y]\n",
    "\n",
    "        for x in range(0, width):\n",
    "            score = scoresData[x]\n",
    "\n",
    "            if(score < scoreThreshold):\n",
    "                continue\n",
    "\n",
    "            # feature map은 320x320 블롭의 1/4 크기이므로, 다시 4배 확대\n",
    "            offsetX = x * 4.0\n",
    "            offsetY = y * 4.0\n",
    "            angle = anglesData[x]\n",
    "\n",
    "            # (offsetX, offsetY) 위치에서 회전된 사각형 정보 추출\n",
    "            cosA = math.cos(angle)\n",
    "            sinA = math.sin(angle)\n",
    "            h = x0_data[x] + x2_data[x]\n",
    "            w = x1_data[x] + x3_data[x]\n",
    "\n",
    "            # 회전된 사각형의 한쪽 모서리 점 좌표 계산\n",
    "            offset = ([offsetX + cosA * x1_data[x] + sinA * x2_data[x],\n",
    "                       offsetY - sinA * x1_data[x] + cosA * x2_data[x]])\n",
    "\n",
    "            # 회전된 사각형의 대각선에 위치한 두 모서리 점 좌표 계산\n",
    "            p1 = (-sinA * h + offset[0], -cosA * h + offset[1])\n",
    "            p3 = (-cosA * w + offset[0],  sinA * w + offset[1])\n",
    "            center = ((p1[0]+p3[0])/2, (p1[1]+p3[1])/2)\n",
    "\n",
    "            detections.append((center, (w, h), -1*angle * 180.0 / math.pi))\n",
    "            confidences.append(float(score))\n",
    "\n",
    "    return [detections, confidences]\n",
    "\n",
    "\n",
    "# 모델 & 설정 파일\n",
    "model = 'EAST/frozen_east_text_detection.pb'\n",
    "confThreshold = 0.5\n",
    "nmsThreshold = 0.4\n",
    "\n",
    "# 테스트 이미지 파일\n",
    "img_files = ['road_closed.jpg', 'patient.jpg', 'copy_center.jpg']\n",
    "\n",
    "# 네트워크 생성\n",
    "net = cv2.dnn.readNet(model)\n",
    "\n",
    "if net.empty():\n",
    "    print('Net open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# 출력 레이어 이름 받아오기\n",
    "'''\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "print(output_layers)\n",
    "'''\n",
    "\n",
    "# 실행\n",
    "\n",
    "for f in img_files:\n",
    "    img = cv2.imread(f)\n",
    "\n",
    "    if img is None:\n",
    "        continue\n",
    "\n",
    "    # 블롭 생성 & 추론\n",
    "    blob = cv2.dnn.blobFromImage(img, 1, (320, 320), (123.68, 116.78, 103.94), True)\n",
    "    net.setInput(blob)\n",
    "    scores, geometry = net.forward(['feature_fusion/Conv_7/Sigmoid', 'feature_fusion/concat_3'])\n",
    "\n",
    "    # scores.shape=(1, 1, 80, 80)\n",
    "    # geometry.shape=(1, 5, 80, 80)\n",
    "\n",
    "    # score가 confThreshold보다 큰 RBOX 정보를 RotatedRect 형식으로 변환하여 반환\n",
    "    [boxes, confidences] = decode(scores, geometry, confThreshold)\n",
    "\n",
    "    # 회전된 사각형에 대한 비최대 억제\n",
    "    indices = cv2.dnn.NMSBoxesRotated(boxes, confidences, confThreshold, nmsThreshold)\n",
    "\n",
    "    rw = img.shape[1] / 320\n",
    "    rh = img.shape[0] / 320\n",
    "\n",
    "    for i in indices:\n",
    "        # 회전된 사각형의 네 모서리 점 좌표 계산 & 표시\n",
    "        vertices = cv2.boxPoints(boxes[i])\n",
    "\n",
    "        for j in range(4):\n",
    "            vertices[j][0] *= rw\n",
    "            vertices[j][1] *= rh\n",
    "\n",
    "        for j in range(4):\n",
    "            # p1 = (vertices[j][0], vertices[j][1])\n",
    "            # p2 = (vertices[(j + 1) % 4][0], vertices[(j + 1) % 4][1])\n",
    "            p1 = (int(vertices[j][0]), int(vertices[j][1]))\n",
    "            p2 = (int(vertices[(j + 1) % 4][0]), int(vertices[(j + 1) % 4][1]))\n",
    "            cv2.line(img, p1, p2, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('img', img)\n",
    "    cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
